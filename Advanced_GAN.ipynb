{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1VsaTQUFO9Ra5cR82DN4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnathonGil/Generative-Artificial-Networks-Study/blob/main/Advanced_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMqBPnqRVLIu"
      },
      "outputs": [],
      "source": [
        "# Advanced GAN\n",
        "# https://medium.com/@ideami\n",
        "\n",
        "# Importing the Libraries\n",
        "import torch, torchvision, os, PIL, pdb\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show(tensor, num = 25, wandbactive = 0, name = ''):\n",
        "  data = tensor.detach().cpu()\n",
        "  grid = make_grid(data[:num], nrow=5).permute(1,2,0)\n",
        "\n",
        "  # Optional\n",
        "  if (wandbactive == 1):\n",
        "    wandb.log({name:wandb.Image(grid.numpy().clip(0,1))})\n",
        "\n",
        "  plt.imshow(grid.clip(0,1))\n",
        "  plt.show()\n",
        "\n",
        "# Hyperparameters and general parameters\n",
        "\n",
        "n_epochs = 10000\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "z_dim = 200\n",
        "device = 'cuda' #GPU\n",
        "\n",
        "cur_step = 0\n",
        "crit_cycles = 5\n",
        "gen_losses = []\n",
        "crit_losses = []\n",
        "show_step = 35\n",
        "save_step = 35\n",
        "\n",
        "wandbact = 1 # True, track statistics of the learning processes through weights and biases\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Optional\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login(key = 'aeca1fda4422b59db5390af38009e15f0524d5f3')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAzS-jp7Z8F6",
        "outputId": "0ce2ab20-605f-4ba1-cc26-09cba7b0627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "experiment_name = wandb.util.generate_id()\n",
        "\n",
        "myrun=wandb.init(\n",
        "    project=\"Wasserstein GAN\",\n",
        "    group = experiment_name,\n",
        "    config={\n",
        "        \"optimizer\":\"adam\",\n",
        "        \"model\":\"wgan gp\",\n",
        "        \"epoch\":\"1000\",\n",
        "        \"batch_size\":128\n",
        "    }\n",
        ")\n",
        "\n",
        "config = wandb.config"
      ],
      "metadata": {
        "id": "XyI-uCQiai_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(experiment_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNcKJ4AYb3n_",
        "outputId": "1e4f2c05-4dda-42bd-8fde-eadb0aff2f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mohrho7l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim=64, d_dim=16):\n",
        "    super(Generator, self).__init__()\n",
        "    self.z_dim = z_dim\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        ## Calculating new Width and Height: (n-1) * stride - 2 * padding + ks\n",
        "        ## n = width or height\n",
        "        ## ks = kernal size\n",
        "        ## We will begin with 1*1 image with z_dim number of channels (200)\n",
        "        nn.ConvTranspose2d(z_dim, d_dim * 32, 4, 1, 0), # 4*4 (ch:200 -> 512)\n",
        "        nn.BatchNorm2d(d_dim*32),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(d_dim*32, d_dim*16, 4, 2, 1), # 8*8 (ch:512 -> 256)\n",
        "        nn.BatchNorm2d(d_dim*16),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(d_dim*16, d_dim*8, 4, 2, 1), # 16*16 (ch:256 -> 128)\n",
        "        nn.BatchNorm2d(d_dim*8),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(d_dim*8, d_dim*4, 4, 2, 1), # 32*32 (ch:128 -> 64)\n",
        "        nn.BatchNorm2d(d_dim*4),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(d_dim*4, d_dim*2, 4, 2, 1), # 64*64 (ch:64 -> 32)\n",
        "        nn.BatchNorm2d(d_dim*2),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(d_dim*2, 3, 4, 2, 1), # 128*128 (ch:32 -> 3)\n",
        "        nn.Tanh() # Produces result in the range from -1 to 1\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "    x = noise.view(len(noise), self.z_dim, 1, 1) # 128 x 200 x 1 x 1\n",
        "    return self.gen(x)\n",
        "\n",
        "def gen_noise(num, z_dim, device='cuda'):\n",
        "  return torch.randn(num, z_dim, device = device) # 128 x 200\n"
      ],
      "metadata": {
        "id": "1xmQT9oQb7Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Critic model\n",
        "\n",
        "class Critic(nn.Module):\n",
        "  def __init__(self, d_dim=16):\n",
        "    super(Critic, self).__init__()\n",
        "\n",
        "    self.crit = nn.Sequential(\n",
        "        # Conv2D in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "        # New width and height: # (n+2*pad-ks)/stride + 1\n",
        "        nn.Conv2d(3, d_dim, 4, 2, 1), # (ch:3 -> 16)\n",
        "        nn.InstanceNorm2d(d_dim),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(d_dim, d_dim*2, 4, 2, 1),  # 32x32 (ch:16 -> 32)\n",
        "        nn.InstanceNorm2d(d_dim*2),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(d_dim*2, d_dim*4, 4, 2, 1),  # 16x16 (ch:32 -> 64)\n",
        "        nn.InstanceNorm2d(d_dim*4),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(d_dim*4, d_dim*8, 4, 2, 1),  # 8x8 (ch:64 -> 128)\n",
        "        nn.InstanceNorm2d(d_dim*8),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(d_dim*8, d_dim*16, 4, 2, 1), # 4x4 (ch:128 -> 256)\n",
        "        nn.InstanceNorm2d(d_dim*16),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(d_dim*16, 1, 4, 1, 0),  # (ch:256 -> 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "    # image 128 * 3 * 128 * 128\n",
        "    crit_pred = self.crit(image) # 128 x 1 x 1 x 1\n",
        "    return crit_pred.view(len(crit_pred), -1) # 128 x 1"
      ],
      "metadata": {
        "id": "2DnQ1qq-VTvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Optional, Initialize your weights in a different way\n",
        "\n",
        "def init_weights(m):\n",
        "  if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "    torch.nn.init.normal_(m.weight, 0.0, 0.2)\n",
        "    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "  if isinstance(m, nn.BatchNorm2d):\n",
        "    torch.nn.init.normal_(m.weight, 0.0, 0.2)\n",
        "    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# gen=gen.apply(init_weights)\n",
        "# crit=crit.apply(init_weights)"
      ],
      "metadata": {
        "id": "YwyjSVUzsKqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "import gdown, zipfile\n",
        "\n",
        "url = 'https://dl.dropboxusercontent.com/scl/fi/vltmt8hlgdf9mv9kn7d0b/img_align_celeba.zip?rlkey=tacwpkr8d9bjpctdftjg3b00a'\n",
        "path = 'data/celeba'\n",
        "download_path=f'{path}/img_align_celeba.zip'\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "gdown.download(url, download_path, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(download_path, 'r') as ziphandler:\n",
        "  ziphandler.extractall(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "umYCC7vRuDGF",
        "outputId": "9ae83ad3-6901-4cd3-d0d7-d1df39a9aacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://dl.dropboxusercontent.com/scl/fi/vltmt8hlgdf9mv9kn7d0b/img_align_celeba.zip?rlkey=tacwpkr8d9bjpctdftjg3b00a\n",
            "To: /content/data/celeba/img_align_celeba.zip\n",
            " 13%|█▎        | 195M/1.44G [00:01<00:07, 157MB/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-67053a885c5b>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mziphandler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset, DataLoader, Declare Genarator and Critic, Test Dataset\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  def __init__(self, path, size=128, lim=10000):\n",
        "    self.sizes=[size,size]\n",
        "    items, labels = [],[]\n",
        "\n",
        "    for data in os.listdir(path)[:lim]:\n",
        "      #path: './data/celeba/img_align_celeb'\n",
        "      #data: '114568.jpg'\n",
        "      item = os.path.join(path,data)\n",
        "      items.append(item)\n",
        "      labels.append(data)\n",
        "\n",
        "    self.items = items\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.items)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    data = PIL.Image.open(self.items[idx]).convert('RGB') # image size = (width, height)\n",
        "    data = np.asarray(torchvision.transforms.Resize(self.sizes)(data)) # Our case: 128 x 128 x 3\n",
        "    data = np.transpose(data, (2,0,1)).astype(np.float32, copy=False) # Our case: 3 x 128 x 128\n",
        "    data = torch.from_numpy(data).div(255) # from 0 to 1\n",
        "    return data, self.labels[idx]\n",
        "\n",
        "# Instantiate the Dataset\n",
        "\n",
        "data_path = './data/celeba/img_align_celeba'\n",
        "ds = Dataset(data_path, size=128, lim=10000)\n",
        "\n",
        "dataloader = DataLoader(ds, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "# Models\n",
        "gen = Generator(z_dim).to(device)\n",
        "crit = Critic().to(device)\n",
        "\n",
        "# Optimizer\n",
        "\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(0.5,0.9))\n",
        "crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(0.5,0.9))\n",
        "\n",
        "# Initializations\n",
        "# gen=gen.apply(init_weights)\n",
        "# crit=crit.apply(init_weights)\n",
        "\n",
        "# Wandb Optional\n",
        "if (wandbact==1):\n",
        "  wandb.watch(gen, log_freq=100)\n",
        "  wandb.watch(crit, log_freq=100)\n",
        "\n",
        "x,y=next(iter(dataloader))\n",
        "show(x)"
      ],
      "metadata": {
        "id": "Fyuw-AJkxR0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Penalty Calculation\n",
        "\n",
        "def get_gp(real, fake, crit, alpha, gamma=10):\n",
        "  mix_images = real * alpha + fake * (1-alpha) # 128 x 3 128 x 128\n",
        "  mix_scores = crit(mix_images) # 128 x 1\n",
        "\n",
        "  gradient = torch.autograd.grad(\n",
        "      inputs = mix_images,\n",
        "      outputs = mix_scores,\n",
        "      grad_outputs = torch.ones_like(mix_scores),\n",
        "      retain_graph = True,\n",
        "      create_graph = True,\n",
        "  )[0] # 128 x 3 128 x 128\n",
        "\n",
        "  gradient = gradient.view(len(gradient), -1) # 128 x 49152\n",
        "  gradient_norm = gradient.norm(2, dim=1)\n",
        "  gp = gamma * ((gradient_norm - 1)**2).mean()\n",
        "\n",
        "  return gp"
      ],
      "metadata": {
        "id": "iYfIOosHL-uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and Load Checkpoints\n",
        "\n",
        "root_path='./data/'\n",
        "\n",
        "def save_checkpoint(name):\n",
        "\n",
        "  torch.save({\n",
        "         'epoch': epoch,\n",
        "         'model_state_dict': gen.state_dict(),\n",
        "         'optimizer_state_dict': gen_opt.state_dict(),\n",
        "  }, f\"{root_path}G-{name}.pkl\")\n",
        "\n",
        "  torch.save({\n",
        "         'epoch': epoch,\n",
        "         'model_state_dict': crit.state_dict(),\n",
        "         'optimizer_state_dict': crit_opt.state_dict(),\n",
        "  }, f\"{root_path}C-{name}.pkl\")\n",
        "\n",
        "  print(\"Saved checkpoint\")\n",
        "\n",
        "def load_checkpoint(name):\n",
        "\n",
        "  checkpoint = torch.load(f\"{root_path}G-{name}.pkl\")\n",
        "  gen.load_state_dict(checkpoint['model_state_dict'])\n",
        "  gen_opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  checkpoint = torch.load(f\"{root_path}C-{name}.pkl\")\n",
        "  crit.load_state_dict(checkpoint['model_state_dict'])\n",
        "  crit_opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  print(\"Loaded checkpoint\")\n"
      ],
      "metadata": {
        "id": "qgGBb68gOIBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for real, _ in tqdm(dataloader):\n",
        "    cur_bs = len(real)\n",
        "    real = real.to(device)\n",
        "\n",
        "    # Critic\n",
        "    mean_crit_loss = 0\n",
        "    for _ in range(crit_cycles):\n",
        "      crit_opt.zero_grad()\n",
        "\n",
        "      noise = gen_noise(cur_bs, z_dim)\n",
        "      fake = gen(noise)\n",
        "      crit_fake_pred = crit(fake.detach())\n",
        "      crit_real_pred = crit(real)\n",
        "\n",
        "      alpha = torch.rand(len(real), 1, 1, 1, device = device, requires_grad = True) # 128 x 1 x 1 x 1\n",
        "      gp = get_gp(real, fake.detach(), crit, alpha)\n",
        "\n",
        "      crit_loss = crit_fake_pred.mean() - crit_real_pred.mean() + gp\n",
        "\n",
        "      mean_crit_loss += crit_loss.item() / crit_cycles\n",
        "\n",
        "      crit_loss.backward(retain_graph=True)\n",
        "      crit_opt.step()\n",
        "\n",
        "    crit_losses+=[mean_crit_loss]\n",
        "\n",
        "    # Generator\n",
        "\n",
        "    gen_opt.zero_grad()\n",
        "    noise = gen_noise(cur_bs, z_dim)\n",
        "    fake = gen(noise)\n",
        "    crit_fake_pred = crit(fake)\n",
        "\n",
        "    gen_loss = -crit_fake_pred.mean()\n",
        "    gen_loss.backward()\n",
        "    gen_opt.step()\n",
        "\n",
        "    gen_losses+=[gen_loss.item()]\n",
        "\n",
        "    # Statistics\n",
        "\n",
        "    if (wandbact == 1):\n",
        "      wandb.log({'Epoch': epoch, 'Step': cur_step, 'Critic Loss':mean_crit_loss, 'Generator Loss':gen_loss})\n",
        "\n",
        "    if cur_step % save_step == 0 and cur_step > 0:\n",
        "      print(\"Saving checkpoint: \", cur_step, save_step)\n",
        "      save_checkpoint(\"latest\")\n",
        "\n",
        "    if (cur_step % show_step == 0 and cur_step > 0):\n",
        "      show(fake, wandbactive=1, name='fake')\n",
        "      show(real, wandbactive=1, name='real')\n",
        "\n",
        "      gen_mean=sum(gen_losses[-show_step:]) / show_step\n",
        "      crit_mean=sum(crit_losses[-show_step:]) / show_step\n",
        "      print(f\"Epoch: {epoch}: Step {cur_step}: Generator Loss:{gen_mean}, Critic Loss:{crit_mean}\")\n",
        "\n",
        "      plt.plot(\n",
        "          range(len(gen_losses)),\n",
        "          torch.Tensor(gen_losses),\n",
        "          label=\"Generator Loss\"\n",
        "      )\n",
        "\n",
        "      plt.plot(\n",
        "          range(len(gen_losses)),\n",
        "          torch.Tensor(crit_losses),\n",
        "          label=\"Critic Loss\"\n",
        "      )\n",
        "\n",
        "      plt.ylim(-1000,1000)\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "    cur_step += 1"
      ],
      "metadata": {
        "id": "XdHeCupvRQon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate New Faces\n",
        "\n",
        "noise = gen_noise(batch_size, z_dim)\n",
        "fake = gen(noise)\n",
        "show(fake)"
      ],
      "metadata": {
        "id": "cycqpMI7aErf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(fake[4].detach().cpu().permute(1,2,0).squeeze().clip(0,1))"
      ],
      "metadata": {
        "id": "8kHx2oeaaoTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Morphing (interpolation between points in latent space)\n",
        "\n",
        "gen_set=[]\n",
        "z_shape=[1, 200, 1, 1]\n",
        "rows=4\n",
        "steps=17\n",
        "\n",
        "for i in range(rows):\n",
        "  z1, z2 = torch.randn(z_shape), torch.randn(z_shape)\n",
        "  for alpha in np.linspace(0, 1, steps):\n",
        "    z = alpha*z1 + (1-alpha)*z2\n",
        "    res=gen(z.cuda())[0]\n",
        "    gen_set.append(res)\n",
        "\n",
        "fig = plt.figure(figsize=(25,11))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(rows,steps), axes_pad = 0.1)\n",
        "\n",
        "for ax, img in zip (grid, gen_set):\n",
        "  ax.axis('off')\n",
        "  res = img.cpu().detach().permute(1, 2, 0)\n",
        "  res = res - res.min()\n",
        "  res = res/ res.max() - res.min()\n",
        "  ax.imshow(res)\n",
        "\n"
      ],
      "metadata": {
        "id": "aG4XAM3ia67c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}